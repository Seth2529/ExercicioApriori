!pip install pandas
!pip install mlxtend
!pip install pandas --upgrade
!pip install mlxtend --upgrade


import pandas as pd
from mlxtend.frequent_patterns import apriori

def load_transactional_data(file_path):
    with open(file_path, 'r') as file:
        return [line.strip().split(',') for line in file]

file_path = "data2.csv"  

transactions = load_transactional_data(file_path)

def convert_to_binary_df(transactions):
    unique_items = sorted(set(item for transaction in transactions for item in transaction))
    binary_df = pd.DataFrame(False, index=range(len(transactions)), columns=unique_items)
    for i, transaction in enumerate(transactions):
        binary_df.loc[i, transaction] = True
    return binary_df

binary_df = convert_to_binary_df(transactions)

def generate_association_rules(frequent_itemsets, min_confidence):
    rules = []
    for i, row in frequent_itemsets.iterrows():
        itemset = row['itemsets']
        suporte_itemset = row['support']
        
        if len(itemset) > 1:
            itemset = list(itemset)
            for antecedente_tamanho in range(1, len(itemset)):
                from itertools import combinations
                for antecedente in combinations(itemset, antecedente_tamanho):
                    antecedente = set(antecedente)
                    consequente = set(itemset) - antecedente
                    
                    suporte_antecedente = frequent_itemsets[
                        frequent_itemsets['itemsets'] == antecedente
                    ]['support'].values
                    
                    if len(suporte_antecedente) > 0:
                        suporte_antecedente = suporte_antecedente[0]
                        confianca = suporte_itemset / suporte_antecedente
                        if confianca >= min_confidence:
                            suporte_consequente = frequent_itemsets[
                                frequent_itemsets['itemsets'] == consequente
                            ]['support'].values
                            if len(suporte_consequente) > 0:
                                suporte_consequente = suporte_consequente[0]
                                lift = confianca / suporte_consequente
                                rules.append({
                                    'antecedente': antecedente,
                                    'consequente': consequente,
                                    'suporte': suporte_itemset,
                                    'confianca': confianca,
                                    'lift': lift
                                })
    return pd.DataFrame(rules)

frequent_itemsets_1 = apriori(binary_df, min_support=0.5, use_colnames=True)
rules_1 = generate_association_rules(frequent_itemsets_1, min_confidence=0.5)

frequent_itemsets_2 = apriori(binary_df, min_support=0.5, use_colnames=True)
rules_2 = generate_association_rules(frequent_itemsets_2, min_confidence=0.75)

print("### Cenário 1: Suporte = 50%, Confiança = 50% ###")
print("Regras:\n", rules_1.rename(columns={
    'antecedente': 'Antecedente',
    'consequente': 'Consequente',
    'suporte': 'Suporte',
    'confianca': 'Confiança',
    'lift': 'Efeito (Lift)'
}))

print("\n\n### Cenário 2: Suporte = 50%, Confiança = 75% ###")
print("Regras:\n", rules_2.rename(columns={
    'antecedente': 'Antecedente',
    'consequente': 'Consequente',
    'suporte': 'Suporte',
    'confianca': 'Confiança',
    'lift': 'Efeito (Lift)'
}))

print("\n\n### Conclusões ###")
print(f"Total de regras no Cenário 1: {len(rules_1)}")
print(f"Total de regras no Cenário 2: {len(rules_2)}")
